{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive"
      ],
      "metadata": {
        "id": "KnKqcE3QFOE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "xpOGmpUMFMZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"
      ],
      "metadata": {
        "id": "d8Zicg_EFiFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community\n",
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
        "!pip install torch==2.0.1\n",
        "# üöÄ ‡∏•‡∏ö PyTorch ‡πÅ‡∏•‡∏∞ Transformers ‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "!pip uninstall -y torch torchvision torchaudio transformers\n",
        "\n",
        "# üöÄ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö CUDA ‡∏Ç‡∏≠‡∏á Colab (CUDA 11.8)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# üöÄ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Transformers ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö\n",
        "!pip install transformers --upgrade\n"
      ],
      "metadata": {
        "id": "RohXzJ6OFkJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏™‡∏£‡πâ‡∏≤‡∏á Evaluation dataset ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©"
      ],
      "metadata": {
        "id": "pR1ScqPPFRgY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qbA4LSkE5DT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# üîë API Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Together\n",
        "api_key = \"xxxx\"  # üëà ‡πÉ‡∏™‡πà Together API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà\n",
        "embedding_file = '/content/drive/MyDrive/LockLearn/recommendations_with_categories.json'\n",
        "output_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "\n",
        "with open(embedding_file, 'r', encoding='utf-8') as f:\n",
        "    recommendations_with_categories = json.load(f)\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
        "def request_with_retry(prompt, retries=3, delay=10):  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏Ç‡∏≠\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    json_data = {\n",
        "        \"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.post(\"https://api.together.xyz/v1/chat/completions\", headers=headers, json=json_data, timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                return response.json().get(\"choices\", [])[0][\"message\"][\"content\"]\n",
        "            elif response.status_code == 429:  # ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏π‡∏Å rate-limited\n",
        "                print(\"‚ùå Rate limit reached. Sleeping for 60 seconds...\")\n",
        "                time.sleep(60)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á 60 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ñ‡πâ‡∏≤‡πÇ‡∏î‡∏ô rate limit\n",
        "            else:\n",
        "                print(f\"‚ùå Error (Status {response.status_code}): {response.text}\")\n",
        "                time.sleep(delay)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ùå Connection Error: {e}\")\n",
        "            time.sleep(delay)\n",
        "    return None\n",
        "\n",
        "# üöÄ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà\n",
        "category_dict = {}\n",
        "for rec in recommendations_with_categories:\n",
        "    category = rec.get('category', 'Unknown')\n",
        "    category_dict.setdefault(category, []).append(rec)\n",
        "\n",
        "# üöÄ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 100)\n",
        "filtered_recommendations = [rec for recs in category_dict.values() for rec in (recs if len(recs) <= 100 else random.sample(recs, 100))]\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤\n",
        "evaluation_data = []\n",
        "print(f\"‚úÖ ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(filtered_recommendations)}\")\n",
        "\n",
        "for i, rec in enumerate(filtered_recommendations):\n",
        "    # ‡∏õ‡∏£‡∏±‡∏ö prompt ‡πÉ‡∏´‡πâ LLM ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "    prompt = f\"Generate a short, human-like question based on the following recommendation: {rec['text']}\"\n",
        "\n",
        "    print(f\"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà {i + 1}\")\n",
        "    question = request_with_retry(prompt, delay=10)  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏Ç‡∏≠\n",
        "\n",
        "    if question:\n",
        "        entry = {\"question\": question.strip(), \"answer\": rec['text'], \"category\": rec.get('category', 'Unknown')}\n",
        "        evaluation_data.append(entry)\n",
        "\n",
        "    # ‡∏´‡∏ô‡πà‡∏ß‡∏á 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏≥‡∏Ç‡∏≠\n",
        "    time.sleep(1)\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö JSON Pretty\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(evaluation_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(evaluation_data)}\")\n",
        "\n",
        "# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö 1,370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "if len(evaluation_data) == 1370:\n",
        "    print(\"‚úÖ ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö 1,370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡πâ‡∏ß!\")\n",
        "else:\n",
        "    print(f\"‚ùå ‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏µ {len(evaluation_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å 1,370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡πÑ‡∏ß‡πâ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import Together\n",
        "import requests\n",
        "import time\n",
        "import json\n"
      ],
      "metadata": {
        "id": "1BancJVuFrDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ embed ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"
      ],
      "metadata": {
        "id": "We79NpInF295"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Tokenizer (Hugging Face)\n",
        "model_name = \"intfloat/multilingual-e5-large-instruct\"  # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô Vector Database\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16)  # ‡πÉ‡∏ä‡πâ Half-Precision ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
        "def embed_text_batch(texts):\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "    return embeddings\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (Batch)\n",
        "batch_size = 10  # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô batch ‡∏•‡∏∞ 10 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
        "all_embeddings = []\n",
        "\n",
        "for i in range(0, len(evaluation_data), batch_size):\n",
        "    batch_questions = [item['question'] for item in evaluation_data[i:i + batch_size]]\n",
        "\n",
        "    batch_embeddings = embed_text_batch(batch_questions)\n",
        "    all_embeddings.extend(batch_embeddings.tolist())\n",
        "\n",
        "    print(f\"‚úÖ batch ‡∏ó‡∏µ‡πà {i // batch_size + 1} embed ‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "\n",
        "    # üöÄ ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå Cache ‡∏Ç‡∏≠‡∏á GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥\n",
        "    if device == torch.device(\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# üöÄ ‡πÄ‡∏û‡∏¥‡πà‡∏° Embeddings ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ Evaluation Dataset\n",
        "for i, item in enumerate(evaluation_data):\n",
        "    item['embedding'] = all_embeddings[i]\n",
        "\n",
        "print(\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Evaluation Dataset ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "\n",
        "# üöÄ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå (Google Drive)\n",
        "output_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(evaluation_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏ó‡∏µ‡πà: {output_file}\")\n"
      ],
      "metadata": {
        "id": "edZ8tlPEF2NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö vector database"
      ],
      "metadata": {
        "id": "yXoNZlmKF-kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ 2. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma Database ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'  # ‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏Ç‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î Collection ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "print(\"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n"
      ],
      "metadata": {
        "id": "p3KHbmV7GA8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏ä‡πâ RAG ‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ embed ‡πÄ‡πÄ‡∏•‡πâ‡∏ß‡πÄ‡πÄ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏±‡∏ö vector database ‡πÑ‡∏î‡πâ‡∏°‡∏±‡πâ‡∏¢"
      ],
      "metadata": {
        "id": "QUdEwrhMGBkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(question_embedding, top_k=3):\n",
        "    results = collection.query(\n",
        "        query_embeddings=[question_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    if results['documents']:\n",
        "        return results['documents'][0]\n",
        "    return []\n",
        "\n",
        "print(\"‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏î‡πâ‡∏ß‡∏¢ RAG\")\n",
        "\n",
        "# üöÄ ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏£‡∏Å\n",
        "test_question = evaluation_data[0]['question']\n",
        "test_embedding = evaluation_data[0]['embedding']\n",
        "\n",
        "recommendations = retrieve_recommendations(test_embedding)\n",
        "print(f\"\\nüîé ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {test_question}\\n‚úÖ ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á:\\n\")\n",
        "\n",
        "for idx, rec in enumerate(recommendations, 1):\n",
        "    print(f\"{idx}. {rec}\")\n"
      ],
      "metadata": {
        "id": "4frvDsrSGK2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏ä‡πâ RAG ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏∂‡∏á‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏°‡∏≤ 3 ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö"
      ],
      "metadata": {
        "id": "UIz1F8iWG-ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG (Retrieve) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(query_embedding, top_k=3):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# üöÄ ‡πÉ‡∏ä‡πâ RAG ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=3)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(evaluation_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG ‡∏ó‡∏µ‡πà: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "rNo0XPWOG-Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Gen ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà RAG ‡∏î‡∏∂‡∏á‡∏°‡∏≤"
      ],
      "metadata": {
        "id": "VSxPzxR7HK8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "\n",
        "# üîë API Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Together\n",
        "api_key = \"xxxxx\"  # üëà ‡πÉ‡∏™‡πà Together API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏° RAG Recommendations\n",
        "input_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2.json'\n",
        "output_file = '/content/drive/MyDrive/LockLearn/optimized_answers_Llama4_scout_v2.json'\n",
        "\n",
        "# üìÇ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "with open(input_file, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
        "if os.path.exists(output_file):\n",
        "    with open(output_file, 'r', encoding='utf-8') as f:\n",
        "        processed_answers = json.load(f)\n",
        "        processed_ids = set([item['question'] for item in processed_answers])\n",
        "else:\n",
        "    processed_answers = []\n",
        "    processed_ids = set()\n",
        "\n",
        "# üîÅ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API\n",
        "def request_with_retry(json_data, retries=3, delay=10):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.post(\"https://api.together.xyz/v1/chat/completions\", headers=headers, json=json_data, timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                answer = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "                if len(answer) > 20:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö\n",
        "                    return answer\n",
        "            print(f\"‚ùå Error (Status {response.status_code}): {response.text}\")\n",
        "            time.sleep(delay)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"‚ùå Connection Error: {e}\")\n",
        "            time.sleep(delay)\n",
        "    return \"\"\n",
        "\n",
        "# üöÄ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏≠‡∏ö\n",
        "for item in data:\n",
        "    if item['question'] in processed_ids:\n",
        "        continue\n",
        "\n",
        "    prompt = f\"Question: {item['question']}\\nRecommendations: {item['recommendations']}\\nAnswer concisely with encouragement.\"\n",
        "    json_data = {\"model\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
        "    answer = request_with_retry(json_data)\n",
        "\n",
        "    if answer:\n",
        "        processed_answers.append({\"question\": item['question'], \"answer\": answer, \"category\": item['category']})\n",
        "        processed_ids.add(item['question'])\n",
        "\n",
        "        # üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(processed_answers, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "        print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ({len(processed_answers)})\")\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•\")\n"
      ],
      "metadata": {
        "id": "KoG00q4tHKS7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}