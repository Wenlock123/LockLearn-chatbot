{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ñ‡∏≥‡πÄ‡πÄ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "\n",
        "*   ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö\n",
        "*   ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ**\n",
        "\n",
        "*    Embedding model ‡∏Ñ‡∏∑‡∏≠ paraphrase-multilingual-MiniLM-L12-v2\n",
        "*    vector database  ‡∏Ç‡∏≠‡∏á Chroma db\n",
        "*    RAG ‡∏Ç‡∏≠‡∏á langchain\n"
      ],
      "metadata": {
        "id": "DlakyaPPAHlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive"
      ],
      "metadata": {
        "id": "KC5Y5lrRAELS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91fyFLVuADW_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"
      ],
      "metadata": {
        "id": "B3SiAclAAg2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch chromadb\n",
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests"
      ],
      "metadata": {
        "id": "SNAhkYaWAm-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests\n"
      ],
      "metadata": {
        "id": "mYs1m_SfCuaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• paraphrase-multilingual-MiniLM-L12-v2  ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Embed"
      ],
      "metadata": {
        "id": "zLTim2uBCWRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def embed_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # mean pooling over token embeddings\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "    return embeddings.cpu().numpy()\n",
        "\n",
        "def embed_recommendations(categorized_recommendations):\n",
        "    for idx, rec in enumerate(categorized_recommendations, start=1):\n",
        "        text = rec['text']\n",
        "        embedding = embed_text(text)\n",
        "        rec['embedding'] = embedding.tolist()\n",
        "        print(f\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ embed ‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "    return categorized_recommendations\n",
        "\n",
        "def save_embeddings_to_file(data, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• embedding ‡∏•‡∏á‡πÉ‡∏ô: {output_file_path}\")\n",
        "\n",
        "def read_recommendations(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "# Main\n",
        "file_path = '/content/drive/MyDrive/LockLearn/recommendations_with_categories.json'  # ‡πÅ‡∏Å‡πâ path ‡∏ï‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
        "recommendations = read_recommendations(file_path)\n",
        "\n",
        "recommendations_with_embeddings = embed_recommendations(recommendations)\n",
        "\n",
        "embedding_output_file = '/content/drive/MyDrive/LockLearn/recommendations_with_embeddings_miniLM.json'\n",
        "save_embeddings_to_file(recommendations_with_embeddings, embedding_output_file)\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ embedding ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏¢‡∏Å\")\n"
      ],
      "metadata": {
        "id": "JkXCBadtCTEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏™‡∏£‡πâ‡∏≤‡∏á vector database"
      ],
      "metadata": {
        "id": "4Uk0KioZC3u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå embeddings ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "embedding_file =   '/content/drive/MyDrive/LockLearn/recommendations_with_embeddings_miniLM.json'\n",
        "with open(embedding_file, 'r', encoding='utf-8') as f:\n",
        "    recommendations_with_embeddings = json.load(f)\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á client ‡πÅ‡∏•‡∏∞ collection\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v4'  # ‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏Ç‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# ‡∏•‡∏ö Collection ‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
        "if \"recommendations\" in [col.name for col in client.list_collections()]:\n",
        "    client.delete_collection(name=\"recommendations\")\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Collection ‡πÉ‡∏´‡∏°‡πà\n",
        "collection = client.get_or_create_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ embedding ‡∏•‡∏á‡πÉ‡∏ô Chroma DB\n",
        "for i, rec in enumerate(recommendations_with_embeddings):\n",
        "    collection.add(\n",
        "        documents=[rec['text']],\n",
        "        embeddings=[rec['embedding']],\n",
        "        metadatas=[{\"category\": rec.get('category', 'Unknown')}],\n",
        "        ids=[f\"rec_{i}\"]\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ embedding ‡∏•‡∏á Chroma DB ‡πÉ‡∏ô Google Drive ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n"
      ],
      "metadata": {
        "id": "rtdA855KC3RR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}