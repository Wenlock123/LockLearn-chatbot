{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ñ‡∏≥‡πÄ‡πÄ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "\n",
        "*   ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö\n",
        "*   ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ**\n",
        "\n",
        "*    Embedding model ‡∏Ñ‡∏∑‡∏≠ BGE-M3\n",
        "*    vector database  ‡∏Ç‡∏≠‡∏á Chroma db\n",
        "*    RAG ‡∏Ç‡∏≠‡∏á langchain\n"
      ],
      "metadata": {
        "id": "DlakyaPPAHlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive"
      ],
      "metadata": {
        "id": "KC5Y5lrRAELS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91fyFLVuADW_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"
      ],
      "metadata": {
        "id": "B3SiAclAAg2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch chromadb\n",
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests"
      ],
      "metadata": {
        "id": "SNAhkYaWAm-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests\n"
      ],
      "metadata": {
        "id": "mYs1m_SfCuaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3  ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Embed"
      ],
      "metadata": {
        "id": "zLTim2uBCWRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3 (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô Hugging Face ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ)\n",
        "model_name = 'BAAI/bge-base-en'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "def embed_recommendations(categorized_recommendations):\n",
        "    for idx, rec in enumerate(categorized_recommendations, start=1):\n",
        "        text = rec['text']\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            # BGE ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏°‡∏µ pooler_output ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ mean pooling ‡∏Ç‡∏≠‡∏á last_hidden_state\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1)  # shape = (1, embedding_dim)\n",
        "\n",
        "        rec['embedding'] = embeddings[0].cpu().numpy().tolist()\n",
        "        print(f\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ embed ‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "\n",
        "    return categorized_recommendations\n",
        "\n",
        "def save_embeddings_to_file(data, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå embedding ‡∏•‡∏á: {output_file_path}\")\n",
        "\n",
        "def read_recommendations(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á\n",
        "file_path = '/content/drive/MyDrive/LockLearn/recommendations_with_categories.json'\n",
        "recommendations = read_recommendations(file_path)\n",
        "\n",
        "recommendations_with_embeddings = embed_recommendations(recommendations)\n",
        "\n",
        "embedding_output_file = '/content/drive/MyDrive/LockLearn/recommendations_with_embeddings_v3_BGE-M3.json'\n",
        "save_embeddings_to_file(recommendations_with_embeddings, embedding_output_file)\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ embedding ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n"
      ],
      "metadata": {
        "id": "JkXCBadtCTEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏™‡∏£‡πâ‡∏≤‡∏á vector database"
      ],
      "metadata": {
        "id": "4Uk0KioZC3u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå embeddings ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
        "embedding_file =  '/content/drive/MyDrive/LockLearn/recommendations_with_embeddings_v3_BGE-M3.json'\n",
        "with open(embedding_file, 'r', encoding='utf-8') as f:\n",
        "    recommendations_with_embeddings = json.load(f)\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á client ‡πÅ‡∏•‡∏∞ collection\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v3'  # ‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏Ç‡∏≠‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# ‡∏•‡∏ö Collection ‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
        "if \"recommendations\" in [col.name for col in client.list_collections()]:\n",
        "    client.delete_collection(name=\"recommendations\")\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Collection ‡πÉ‡∏´‡∏°‡πà\n",
        "collection = client.get_or_create_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ embedding ‡∏•‡∏á‡πÉ‡∏ô Chroma DB\n",
        "for i, rec in enumerate(recommendations_with_embeddings):\n",
        "    collection.add(\n",
        "        documents=[rec['text']],\n",
        "        embeddings=[rec['embedding']],\n",
        "        metadatas=[{\"category\": rec.get('category', 'Unknown')}],\n",
        "        ids=[f\"rec_{i}\"]\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ embedding ‡∏•‡∏á Chroma DB ‡πÉ‡∏ô Google Drive ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n"
      ],
      "metadata": {
        "id": "rtdA855KC3RR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}