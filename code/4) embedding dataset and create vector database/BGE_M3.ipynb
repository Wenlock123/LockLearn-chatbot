{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ñ‡∏≥‡πÄ‡πÄ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "\n",
        "*   ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö\n",
        "*   ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ**\n",
        "\n",
        "*    Embedding model ‡∏Ñ‡∏∑‡∏≠ BGE - M3\n",
        "*    vector database  ‡∏Ç‡∏≠‡∏á Chroma db\n",
        "*    RAG ‡∏Ç‡∏≠‡∏á langchain\n"
      ],
      "metadata": {
        "id": "DlakyaPPAHlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive"
      ],
      "metadata": {
        "id": "KC5Y5lrRAELS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91fyFLVuADW_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"
      ],
      "metadata": {
        "id": "B3SiAclAAg2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch chromadb\n",
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests"
      ],
      "metadata": {
        "id": "SNAhkYaWAm-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests\n"
      ],
      "metadata": {
        "id": "mYs1m_SfCuaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE - M3"
      ],
      "metadata": {
        "id": "zLTim2uBCWRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# ‚úÖ ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3\n",
        "model_name = \"BAAI/bge-m3\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ‚úÖ mean pooling function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö BGE\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]  # last_hidden_state\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return (token_embeddings * input_mask_expanded).sum(1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
        "def embed_text(text):\n",
        "    # ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á BGE: prepend ‡∏î‡πâ‡∏ß‡∏¢ \"passage: \" ‡∏´‡∏£‡∏∑‡∏≠ \"query: \" ‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó\n",
        "    text = \"passage: \" + text.strip()\n",
        "\n",
        "    encoded_input = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "\n",
        "    embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "    return embedding.squeeze().cpu().numpy()\n",
        "\n",
        "# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "def embed_recommendations(categorized_recommendations):\n",
        "    for idx, rec in enumerate(categorized_recommendations, start=1):\n",
        "        text = rec['text']\n",
        "        embedding = embed_text(text)\n",
        "        rec['embedding'] = embedding.tolist()\n",
        "        print(f\"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ embed ‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "    return categorized_recommendations\n",
        "\n",
        "# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON\n",
        "def save_embeddings_to_file(data, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• embedding ‡∏•‡∏á‡πÉ‡∏ô: {output_file_path}\")\n",
        "\n",
        "# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "def read_recommendations(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "# ‚úÖ Main\n",
        "file_path = '/content/drive/MyDrive/LockLearn/recommendations_with_categories.json'  # üîÑ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏° path ‡∏à‡∏£‡∏¥‡∏á\n",
        "recommendations = read_recommendations(file_path)\n",
        "\n",
        "recommendations_with_embeddings = embed_recommendations(recommendations)\n",
        "\n",
        "embedding_output_file = '/content/drive/MyDrive/LockLearn/recommendations_with_embeddings_BGE_M3.json'\n",
        "save_embeddings_to_file(recommendations_with_embeddings, embedding_output_file)\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ embedding ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏¢‡∏Å\")\n"
      ],
      "metadata": {
        "id": "JkXCBadtCTEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏™‡∏£‡πâ‡∏≤‡∏á vector database"
      ],
      "metadata": {
        "id": "4Uk0KioZC3u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå embeddings ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å BGE M3\n",
        "embedding_file = '/content/drive/MyDrive/LockLearn/recommendations_with_embeddings_BGE_M3.json'\n",
        "with open(embedding_file, 'r', encoding='utf-8') as f:\n",
        "    recommendations_with_embeddings = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB v5\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# üîÑ ‡∏•‡∏ö Collection ‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)\n",
        "if \"recommendations\" in [col.name for col in client.list_collections()]:\n",
        "    client.delete_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á Collection ‡πÉ‡∏´‡∏°‡πà\n",
        "collection = client.get_or_create_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• embeddings ‡∏•‡∏á Chroma DB\n",
        "for i, rec in enumerate(recommendations_with_embeddings):\n",
        "    collection.add(\n",
        "        documents=[rec['text']],\n",
        "        embeddings=[rec['embedding']],\n",
        "        metadatas=[{\"category\": rec.get('category', 'Unknown')}],\n",
        "        ids=[f\"rec_{i}\"]\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ embedding ‡∏à‡∏≤‡∏Å BGE M3 ‡∏•‡∏á Chroma DB v5 ‡πÉ‡∏ô Google Drive ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n"
      ],
      "metadata": {
        "id": "rtdA855KC3RR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}