{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏\n",
        "‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á Embedding model\n",
        "\n",
        "*   ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÉ‡∏ä‡πâ ‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE - M3\n",
        "*   ‡∏à‡∏∞‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡πà‡∏≤ Recall@ k   ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
        "\n",
        "\n",
        "\n",
        "‡∏Ñ‡∏≥‡πÄ‡πÄ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "  ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° google drive ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n"
      ],
      "metadata": {
        "id": "fr3ShNjgPO_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oXpCKVWROvrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb41f7f-1924-4fe5-d065-7fc53931994c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"
      ],
      "metadata": {
        "id": "9ARzdOOUQNVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "9yT-NRHVP6Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
        "!pip install torch==2.0.1"
      ],
      "metadata": {
        "id": "W978UZ4FQKad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ ‡∏•‡∏ö PyTorch ‡πÅ‡∏•‡∏∞ Transformers ‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "!pip uninstall -y torch torchvision torchaudio transformers\n",
        "\n",
        "# üöÄ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö CUDA ‡∏Ç‡∏≠‡∏á Colab (CUDA 11.8)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# üöÄ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Transformers ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö\n",
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "id": "ztEphhzAQMWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests"
      ],
      "metadata": {
        "id": "o1EhEINYQ4vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**English Evaluation dataset**"
      ],
      "metadata": {
        "id": "WM9fj3g1S5sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ embed ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á Evaluation datasest ‡∏î‡πâ‡∏ß‡∏¢ BGE-M3"
      ],
      "metadata": {
        "id": "BOgmBsU7QTqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3\n",
        "model_name = \"BAAI/bge-m3\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥ mean pooling ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö embedding\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]  # First element: last_hidden_state\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ö‡∏ö batch\n",
        "def embed_text_batch(texts):\n",
        "    encoded_input = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "\n",
        "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "    return embeddings.cpu().numpy()\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (Batch)\n",
        "batch_size = 10\n",
        "all_embeddings = []\n",
        "\n",
        "for i in range(0, len(evaluation_data), batch_size):\n",
        "    batch_questions = [item['question'] for item in evaluation_data[i:i + batch_size]]\n",
        "    batch_embeddings = embed_text_batch(batch_questions)\n",
        "    all_embeddings.extend(batch_embeddings.tolist())\n",
        "\n",
        "    print(f\"‚úÖ batch ‡∏ó‡∏µ‡πà {i // batch_size + 1} embed ‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# üöÄ ‡πÄ‡∏û‡∏¥‡πà‡∏° Embeddings ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ Evaluation Dataset\n",
        "for i, item in enumerate(evaluation_data):\n",
        "    item['embedding'] = all_embeddings[i]\n",
        "\n",
        "print(\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Evaluation Dataset ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "\n",
        "# üöÄ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "output_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(evaluation_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏ó‡∏µ‡πà: {output_file}\")\n"
      ],
      "metadata": {
        "id": "yj4oLv_OQTC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° vector database"
      ],
      "metadata": {
        "id": "iMQtWvfRQWO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ 2. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma Database v5 ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà\n",
        "import chromadb\n",
        "\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'  # ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô path ‡πÄ‡∏õ‡πá‡∏ô v5\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Collection ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß (‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)\n",
        "collection_name = \"recommendations\"\n",
        "collection = client.get_collection(name=collection_name)\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB v5 ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô 'recommendations' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n"
      ],
      "metadata": {
        "id": "53ghM_8YQc6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏°‡∏±‡πâ‡∏¢"
      ],
      "metadata": {
        "id": "Qk0sdyQ1QdfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏à‡∏≤‡∏Å BGE-M3\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset (BGE-M3) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô v5\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'  # ‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏õ‡πá‡∏ô v5\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Collection \"recommendations\"\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "print(\"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB v5 ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô 'recommendations' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(question_embedding, top_k=3):\n",
        "    results = collection.query(\n",
        "        query_embeddings=[question_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    if results and 'documents' in results and len(results['documents']) > 0:\n",
        "        return results['documents'][0]\n",
        "    return []\n",
        "\n",
        "# üöÄ ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏£‡∏Å\n",
        "test_question = evaluation_data[0]['question']\n",
        "test_embedding = evaluation_data[0]['embedding']\n",
        "\n",
        "recommendations = retrieve_recommendations(test_embedding)\n",
        "print(f\"\\nüîé ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {test_question}\\n‚úÖ ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á:\\n\")\n",
        "\n",
        "for idx, rec in enumerate(recommendations, 1):\n",
        "    print(f\"{idx}. {rec}\")\n"
      ],
      "metadata": {
        "id": "YEztfa-vQhaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ K = 3"
      ],
      "metadata": {
        "id": "trpTKJIdQlx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings (‡∏à‡∏≤‡∏Å BGE-M3)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset (BGE-M3) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô v5\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG (Retrieve) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(query_embedding, top_k=3):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# üöÄ ‡πÉ‡∏ä‡πâ RAG ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=3)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item.get('category', 'Unknown'),\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(evaluation_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_BGE_M3_K=3.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG ‡∏ó‡∏µ‡πà: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "W94zZ9pFQneD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Recall"
      ],
      "metadata": {
        "id": "thtf_YDZQrE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset (‡∏°‡∏µ embeddings)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î RAG Results (‡∏à‡∏≤‡∏Å BGE-M3)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_BGE_M3_K=3.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 3  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r.lower().strip() in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r.lower().strip() in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec.lower().strip() in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# üöÄ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...\")\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n",
        "    if isinstance(item['answer'], list):\n",
        "        relevant_answers = [ans.lower().strip() for ans in item['answer']]\n",
        "    else:\n",
        "        relevant_answers = [item['answer'].lower().strip()]\n",
        "\n",
        "    retrieved = [r.lower().strip() for r in item['recommendations']]\n",
        "\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(rag_results)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\nüîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG (BGE-M3)\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "4wDF8annQslF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e320559-448b-41b6-e58d-918f75c1fa2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 400/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 500/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 600/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 700/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 800/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 900/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1000/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1370/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "\n",
            "üîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG (BGE-M3)\n",
            "Precision@3: 0.180\n",
            "Recall@3: 0.539\n",
            "Mean Reciprocal Rank (MRR): 0.453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ K = 5"
      ],
      "metadata": {
        "id": "vrfKGpKeRSS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings (‡∏à‡∏≤‡∏Å BGE-M3)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset (BGE-M3) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô v5\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG (Retrieve) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(query_embedding, top_k=5):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# üöÄ ‡πÉ‡∏ä‡πâ RAG ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=5)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item.get('category', 'Unknown'),\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(evaluation_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_BGE_M3_K=5.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG ‡∏ó‡∏µ‡πà: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "-u8P7HjRRTt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Recall"
      ],
      "metadata": {
        "id": "nO4V0f81Rjml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset (‡∏°‡∏µ embeddings)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î RAG Results (‡∏à‡∏≤‡∏Å BGE-M3)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_BGE_M3_K=5.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 5  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r.lower().strip() in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r.lower().strip() in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec.lower().strip() in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# üöÄ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...\")\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n",
        "    if isinstance(item['answer'], list):\n",
        "        relevant_answers = [ans.lower().strip() for ans in item['answer']]\n",
        "    else:\n",
        "        relevant_answers = [item['answer'].lower().strip()]\n",
        "\n",
        "    retrieved = [r.lower().strip() for r in item['recommendations']]\n",
        "\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(rag_results)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\nüîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG (BGE-M3)\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "LwF3M9SgRlOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf33f2f-f707-46d3-fe79-8f1bcbe84639"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 400/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 500/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 600/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 700/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 800/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 900/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1000/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1370/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "\n",
            "üîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG (BGE-M3)\n",
            "Precision@5: 0.119\n",
            "Recall@5: 0.596\n",
            "Mean Reciprocal Rank (MRR): 0.467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ K = 10"
      ],
      "metadata": {
        "id": "w_78h8GQRnC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings (‡∏à‡∏≤‡∏Å BGE-M3)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset (BGE-M3) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô v5\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG (Retrieve) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(query_embedding, top_k=10):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# üöÄ ‡πÉ‡∏ä‡πâ RAG ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=10)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item.get('category', 'Unknown'),\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(evaluation_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_BGE_M3_K=10.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG ‡∏ó‡∏µ‡πà: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "OPzfyq5JRose"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Recall"
      ],
      "metadata": {
        "id": "Vza8WlrzRqQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset (‡∏°‡∏µ embeddings)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î RAG Results (‡∏à‡∏≤‡∏Å BGE-M3)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_BGE_M3_K=10.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 10  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r.lower().strip() in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r.lower().strip() in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec.lower().strip() in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# üöÄ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...\")\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n",
        "    if isinstance(item['answer'], list):\n",
        "        relevant_answers = [ans.lower().strip() for ans in item['answer']]\n",
        "    else:\n",
        "        relevant_answers = [item['answer'].lower().strip()]\n",
        "\n",
        "    retrieved = [r.lower().strip() for r in item['recommendations']]\n",
        "\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(rag_results)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\nüîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG (BGE-M3)\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "Ko-Fnp0lRrkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7037f805-ab3c-4101-f18c-bfaae6efb028"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 400/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 500/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 600/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 700/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 800/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 900/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1000/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1370/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "\n",
            "üîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG (BGE-M3)\n",
            "Precision@10: 0.067\n",
            "Recall@10: 0.674\n",
            "Mean Reciprocal Rank (MRR): 0.477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**Thai Evaluation dataset**"
      ],
      "metadata": {
        "id": "WadnUs-BS-3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Embedding ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE - M3"
      ],
      "metadata": {
        "id": "-WiCtO6KTQpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import json\n",
        "\n",
        "# üîß ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö BGE-M3\n",
        "input_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_TH.json'\n",
        "output_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_TH_embedded_BGE_M3.json'\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE-M3 ‡∏à‡∏≤‡∏Å Hugging Face\n",
        "model_name = 'BAAI/bge-m3'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ GPU ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏´‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡∏¢‡πâ‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏ó‡∏µ‡πà device ‡∏ô‡∏±‡πâ‡∏ô\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# üî• ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding ‡∏î‡πâ‡∏ß‡∏¢ mean pooling\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output.last_hidden_state  # ‡πÉ‡∏ä‡πâ last_hidden_state\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "def create_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**inputs)\n",
        "    embedding = mean_pooling(model_output, inputs['attention_mask'])\n",
        "    return embedding[0].cpu().numpy().tolist()\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "with open(input_file, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(data)}\")\n",
        "\n",
        "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
        "for index, item in enumerate(data, start=1):\n",
        "    text = item.get(\"translated_question\", \"\")\n",
        "    if text:\n",
        "        item['question_embedding'] = create_embedding(text)\n",
        "        print(f\"‚úÖ ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà {index} ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding ‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "\n",
        "# üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏î‡πâ‡∏ß‡∏¢ BGE-M3\")\n"
      ],
      "metadata": {
        "id": "FYWXnt7dTCrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test ‡∏ß‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö Evaluation dataset ‡πÑ‡∏î‡πâ‡∏°‡∏±‡πâ‡∏¢"
      ],
      "metadata": {
        "id": "FAOdH7RbTbY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings (‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_TH_embedded_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB (‡πÅ‡∏Å‡πâ path ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà)\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(question_embedding, top_k=3):\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á embedding ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô list (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô numpy array ‡∏´‡∏£‡∏∑‡∏≠ torch tensor ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡πà‡∏≠‡∏ô)\n",
        "    if not isinstance(question_embedding, list):\n",
        "        question_embedding = question_embedding.tolist()\n",
        "\n",
        "    results = collection.query(\n",
        "        query_embeddings=[question_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "print(\"‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏î‡πâ‡∏ß‡∏¢ RAG\")\n",
        "\n",
        "# üöÄ ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏£‡∏Å\n",
        "test_question = evaluation_data[0].get('translated_question', evaluation_data[0].get('question', ''))\n",
        "test_embedding = evaluation_data[0]['question_embedding']\n",
        "\n",
        "recommendations = retrieve_recommendations(test_embedding)\n",
        "print(f\"\\nüîé ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {test_question}\\n‚úÖ ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á:\\n\")\n",
        "\n",
        "for idx, rec in enumerate(recommendations, 1):\n",
        "    print(f\"{idx}. {rec}\")\n"
      ],
      "metadata": {
        "id": "Cvcl0fOqTgWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ K = 3"
      ],
      "metadata": {
        "id": "KIcRS2gjTjQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_TH_embedded_BGE_M3.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Evaluation Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏° Embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {len(evaluation_data)}\")\n",
        "\n",
        "# üöÄ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v5'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô RAG (Retrieve) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á\n",
        "def retrieve_recommendations(query_embedding, top_k=3):\n",
        "    # ‡∏ñ‡πâ‡∏≤ embedding ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà list ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô list ‡∏Å‡πà‡∏≠‡∏ô\n",
        "    if not isinstance(query_embedding, list):\n",
        "        query_embedding = query_embedding.tolist()\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# üöÄ ‡πÉ‡∏ä‡πâ RAG ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    if 'question_embedding' not in item:\n",
        "        print(f\"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏°‡πà‡∏°‡∏µ key 'question_embedding' ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...\")\n",
        "        continue\n",
        "\n",
        "    query_embedding = item['question_embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=3)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item.get('translated_question', ''),\n",
        "        \"answer\": item.get('translated_answer', ''),\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(evaluation_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_TH_BGE_M3_K=3.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG ‡∏ó‡∏µ‡πà: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "nagvoqElTlt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Recall"
      ],
      "metadata": {
        "id": "UWkQqLaMTnlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå evaluation dataset (‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_TH_embedded_BGE_M3.json'  # ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# üöÄ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå RAG (‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° + ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_TH_BGE_M3_K=3.json'  # ‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 3  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ (top_k)\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# üöÄ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# üöÄ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "    if 'translated_answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà {idx} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...\")\n",
        "        continue\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á str ‡∏´‡∏£‡∏∑‡∏≠ list)\n",
        "    relevant_answers = [item['translated_answer']] if isinstance(item['translated_answer'], str) else item['translated_answer']\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß {idx}/{len(rag_results)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\")\n",
        "\n",
        "# üöÄ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á Precision, Recall, MRR ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\nüîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "KwWycAPaTpku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c775aca-3a6f-44ea-a4aa-540277721318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall, ‡πÅ‡∏•‡∏∞ MRR...\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 400/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 500/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 600/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 700/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 800/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 900/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1000/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1100/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1200/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1300/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß 1370/1370 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°\n",
            "\n",
            "üîé ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ RAG\n",
            "Precision@3: 0.169\n",
            "Recall@3: 0.506\n",
            "Mean Reciprocal Rank (MRR): 0.431\n"
          ]
        }
      ]
    }
  ]
}