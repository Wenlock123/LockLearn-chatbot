{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# หมายเหตุ\n",
        "เป็นการทดลองเพื่อเปรียบเทียบประสิทธิภาพของ Embedding model\n",
        "\n",
        "*   โดยจะใช้ โมเดล test paraphrase-multilingual-MiniLM-L12-v2\n",
        "*   จะเน้นค่า Recall@ k   เท่านั้น\n",
        "\n",
        "\n",
        "\n",
        "คำเเนะนำ\n",
        "  ให้ทำการเชื่อม google drive ก่อนทุกครั้ง\n"
      ],
      "metadata": {
        "id": "fr3ShNjgPO_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oXpCKVWROvrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acf0b3c-3838-4d23-f5d6-f0a27bb6c3b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "โหลดสิ่งที่จำเป็น"
      ],
      "metadata": {
        "id": "9ARzdOOUQNVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "9yT-NRHVP6Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ติดตั้ง PyTorch เวอร์ชันล่าสุด\n",
        "!pip install torch==2.0.1"
      ],
      "metadata": {
        "id": "W978UZ4FQKad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 ลบ PyTorch และ Transformers เก่าทั้งหมด\n",
        "!pip uninstall -y torch torchvision torchaudio transformers\n",
        "\n",
        "# 🚀 ติดตั้ง PyTorch ที่รองรับ CUDA ของ Colab (CUDA 11.8)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# 🚀 ติดตั้ง Transformers เวอร์ชันที่รองรับ\n",
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "id": "ztEphhzAQMWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain transformers chromadb requests\n",
        "!pip install -q langchain chromadb requests"
      ],
      "metadata": {
        "id": "o1EhEINYQ4vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**English Evaluation dataset**"
      ],
      "metadata": {
        "id": "WM9fj3g1S5sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทำการ embed คำถามของ Evaluation datasest ด้วย test paraphrase-multilingual-MiniLM-L12-v2"
      ],
      "metadata": {
        "id": "BOgmBsU7QTqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# 🚀 โหลดโมเดล SentenceTransformer (paraphrase-multilingual-MiniLM-L12-v2)\n",
        "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "model = SentenceTransformer(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # ตั้งเป็นโหมดประเมินผลเพื่อประหยัดหน่วยความจำ\n",
        "\n",
        "# 🚀 ฟังก์ชันสร้าง Embedding ของคำถาม\n",
        "def embed_text_batch(texts):\n",
        "    embeddings = model.encode(\n",
        "        texts,\n",
        "        convert_to_tensor=True,\n",
        "        show_progress_bar=True,\n",
        "        device=device,\n",
        "        batch_size=32  # สามารถปรับ batch size ให้เหมาะสมกับ GPU ได้\n",
        "    )\n",
        "    return embeddings.cpu().numpy()\n",
        "\n",
        "# 🚀 โหลด Evaluation Dataset\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_datasetv2.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"✅ โหลด Evaluation Dataset จำนวนคำถาม-คำตอบ: {len(evaluation_data)}\")\n",
        "\n",
        "# 🚀 สร้าง Embeddings สำหรับคำถามทั้งหมด (Batch)\n",
        "batch_size = 10\n",
        "all_embeddings = []\n",
        "\n",
        "for i in range(0, len(evaluation_data), batch_size):\n",
        "    batch_questions = [item['question'] for item in evaluation_data[i:i + batch_size]]\n",
        "    batch_embeddings = embed_text_batch(batch_questions)\n",
        "    all_embeddings.extend(batch_embeddings.tolist())\n",
        "\n",
        "    print(f\"✅ batch ที่ {i // batch_size + 1} embed แล้ว\")\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# 🚀 เพิ่ม Embeddings กลับเข้า Evaluation Dataset\n",
        "for i, item in enumerate(evaluation_data):\n",
        "    item['embedding'] = all_embeddings[i]\n",
        "\n",
        "print(\"✅ สร้าง Embeddings สำหรับคำถามใน Evaluation Dataset สำเร็จ\")\n",
        "\n",
        "# 🚀 กำหนดเส้นทางที่ต้องการบันทึกไฟล์\n",
        "output_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "\n",
        "# 🚀 บันทึก Evaluation Dataset พร้อม Embeddings ลงไฟล์ JSON\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(evaluation_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"✅ บันทึก Evaluation Dataset พร้อม Embeddings ที่: {output_file}\")\n"
      ],
      "metadata": {
        "id": "yj4oLv_OQTC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เชื่อม vector database"
      ],
      "metadata": {
        "id": "iMQtWvfRQWO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 2. เชื่อมต่อกับ Chroma Database ที่มีอยู่แล้ว\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v4'  # ระบุ path ของฐานข้อมูล\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "\n",
        "# โหลด Collection ที่มีอยู่แล้ว\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "print(\"✅ เชื่อมต่อกับ Chroma DB สำเร็จ\")\n"
      ],
      "metadata": {
        "id": "53ghM_8YQc6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เช็คว่าสามารถดึงข้อมูลได้มั้ย"
      ],
      "metadata": {
        "id": "Qk0sdyQ1QdfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# 🚀 โหลด Evaluation Dataset พร้อม Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"✅ โหลด Evaluation Dataset พร้อม Embeddings จำนวนคำถาม-คำตอบ: {len(evaluation_data)}\")\n",
        "\n",
        "# 🚀 เชื่อมต่อกับ Chroma DB (ใช้ฐานข้อมูล v4)\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v4'\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# 🚀 ฟังก์ชัน RAG ดึงคำแนะนำที่ใกล้เคียง\n",
        "def retrieve_recommendations(question_embedding, top_k=3):\n",
        "    results = collection.query(\n",
        "        query_embeddings=[question_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    if results and 'documents' in results and len(results['documents']) > 0:\n",
        "        return results['documents'][0]\n",
        "    return []\n",
        "\n",
        "print(\"✅ พร้อมสำหรับการค้นหาคำแนะนำด้วย RAG\")\n",
        "\n",
        "# 🚀 ทดลองดึงคำแนะนำที่ใกล้เคียงสำหรับคำถามแรก\n",
        "test_question = evaluation_data[0]['question']\n",
        "test_embedding = evaluation_data[0]['embedding']\n",
        "\n",
        "recommendations = retrieve_recommendations(test_embedding)\n",
        "print(f\"\\n🔎 คำถาม: {test_question}\\n✅ คำแนะนำที่ใกล้เคียง:\\n\")\n",
        "\n",
        "for idx, rec in enumerate(recommendations, 1):\n",
        "    print(f\"{idx}. {rec}\")\n"
      ],
      "metadata": {
        "id": "YEztfa-vQhaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ให้ค่า K = 3"
      ],
      "metadata": {
        "id": "trpTKJIdQlx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# 🚀 โหลด Evaluation Dataset พร้อม Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"✅ โหลด Evaluation Dataset พร้อม Embeddings จำนวนคำถาม-คำตอบ: {len(evaluation_data)}\")\n",
        "\n",
        "# 🚀 เชื่อมต่อกับ Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v4'  # เปลี่ยนเป็น Database ใหม่\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# 🚀 ฟังก์ชัน RAG (Retrieve) เพื่อค้นหาคำแนะนำที่ใกล้เคียง\n",
        "def retrieve_recommendations(query_embedding, top_k=3):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# 🚀 ใช้ RAG ค้นหาคำแนะนำสำหรับทุกคำถามใน Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"🔄 กำลังดึงคำแนะนำที่ใกล้เคียงด้วย RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=3)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"✅ ประมวลผลแล้ว {idx}/{len(evaluation_data)} คำถาม\")\n",
        "\n",
        "# 🚀 บันทึกผลลัพธ์ RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_MiniLM_K=3.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'✅ บันทึกผลลัพธ์ RAG ที่: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "W94zZ9pFQneD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "หาค่า Recall"
      ],
      "metadata": {
        "id": "thtf_YDZQrE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 🚀 โหลดไฟล์ evaluation dataset (คำถาม-คำตอบจริง)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# 🚀 โหลดไฟล์ผลลัพธ์ RAG (คำถาม + คำแนะนำที่ดึงมา)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_MiniLM_K=3.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 3  # จำนวนคำแนะนำที่ดึงมา (top_k)\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# 🚀 เก็บผลลัพธ์คำนวณต่างๆ\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"🔄 กำลังคำนวณ Precision, Recall, และ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    # ตรวจสอบว่ามีคำตอบและคำแนะนำหรือไม่\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"⚠️ ข้อที่ {idx} ไม่มีคำตอบหรือคำแนะนำ ข้ามไป...\")\n",
        "        continue\n",
        "\n",
        "    # คำตอบจริง (ในรูปแบบ list เพื่อรองรับหลายคำตอบในอนาคต)\n",
        "    relevant_answers = [item['answer']] if isinstance(item['answer'], str) else item['answer']\n",
        "\n",
        "    # คำแนะนำที่ดึงมา (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    # คำนวณ Metrics\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"✅ ประมวลผลแล้ว {idx}/{len(rag_results)} คำถาม\")\n",
        "\n",
        "# 🚀 คำนวณค่าเฉลี่ยของ Precision, Recall, MRR ทั้งหมด\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\n🔎 ผลลัพธ์การประเมินผลด้วย RAG\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "id": "4wDF8annQslF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660cdf36-199a-4b6d-be41-ba34cab96312"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 กำลังคำนวณ Precision, Recall, และ MRR...\n",
            "✅ ประมวลผลแล้ว 100/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 200/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 300/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 400/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 500/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 600/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 700/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 800/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 900/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1000/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1100/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1200/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1300/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1370/1370 คำถาม\n",
            "\n",
            "🔎 ผลลัพธ์การประเมินผลด้วย RAG\n",
            "Precision@3: 0.129\n",
            "Recall@3: 0.386\n",
            "Mean Reciprocal Rank (MRR): 0.321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K = 5"
      ],
      "metadata": {
        "id": "68ZE_OOMTwxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# 🚀 โหลด Evaluation Dataset พร้อม Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"✅ โหลด Evaluation Dataset พร้อม Embeddings จำนวนคำถาม-คำตอบ: {len(evaluation_data)}\")\n",
        "\n",
        "# 🚀 เชื่อมต่อกับ Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v4'  # เปลี่ยนเป็น Database ใหม่\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# 🚀 ฟังก์ชัน RAG (Retrieve) เพื่อค้นหาคำแนะนำที่ใกล้เคียง\n",
        "def retrieve_recommendations(query_embedding, top_k=5):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# 🚀 ใช้ RAG ค้นหาคำแนะนำสำหรับทุกคำถามใน Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"🔄 กำลังดึงคำแนะนำที่ใกล้เคียงด้วย RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=5)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"✅ ประมวลผลแล้ว {idx}/{len(evaluation_data)} คำถาม\")\n",
        "\n",
        "# 🚀 บันทึกผลลัพธ์ RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_MiniLM_K=5.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'✅ บันทึกผลลัพธ์ RAG ที่: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "rWmUKBapT5LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "หาค่า Recall"
      ],
      "metadata": {
        "id": "qyKY3apSUGUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 🚀 โหลดไฟล์ evaluation dataset (คำถาม-คำตอบจริง)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# 🚀 โหลดไฟล์ผลลัพธ์ RAG (คำถาม + คำแนะนำที่ดึงมา)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_MiniLM_K=5.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 5  # จำนวนคำแนะนำที่ดึงมา (top_k)\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# 🚀 เก็บผลลัพธ์คำนวณต่างๆ\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"🔄 กำลังคำนวณ Precision, Recall, และ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    # ตรวจสอบว่ามีคำตอบและคำแนะนำหรือไม่\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"⚠️ ข้อที่ {idx} ไม่มีคำตอบหรือคำแนะนำ ข้ามไป...\")\n",
        "        continue\n",
        "\n",
        "    # คำตอบจริง (ในรูปแบบ list เพื่อรองรับหลายคำตอบในอนาคต)\n",
        "    relevant_answers = [item['answer']] if isinstance(item['answer'], str) else item['answer']\n",
        "\n",
        "    # คำแนะนำที่ดึงมา (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    # คำนวณ Metrics\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"✅ ประมวลผลแล้ว {idx}/{len(rag_results)} คำถาม\")\n",
        "\n",
        "# 🚀 คำนวณค่าเฉลี่ยของ Precision, Recall, MRR ทั้งหมด\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\n🔎 ผลลัพธ์การประเมินผลด้วย RAG\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHGqVwh3UIEa",
        "outputId": "10440c46-9d62-414a-cb17-5baca67bfa47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 กำลังคำนวณ Precision, Recall, และ MRR...\n",
            "✅ ประมวลผลแล้ว 100/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 200/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 300/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 400/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 500/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 600/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 700/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 800/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 900/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1000/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1100/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1200/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1300/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1370/1370 คำถาม\n",
            "\n",
            "🔎 ผลลัพธ์การประเมินผลด้วย RAG\n",
            "Precision@5: 0.087\n",
            "Recall@5: 0.436\n",
            "Mean Reciprocal Rank (MRR): 0.333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K = 10"
      ],
      "metadata": {
        "id": "_sV3YT8lTySB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chromadb\n",
        "\n",
        "# 🚀 โหลด Evaluation Dataset พร้อม Embeddings\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "print(f\"✅ โหลด Evaluation Dataset พร้อม Embeddings จำนวนคำถาม-คำตอบ: {len(evaluation_data)}\")\n",
        "\n",
        "# 🚀 เชื่อมต่อกับ Chroma DB\n",
        "db_path = '/content/drive/MyDrive/LockLearn/chromadb_database_v4'  # เปลี่ยนเป็น Database ใหม่\n",
        "client = chromadb.PersistentClient(path=db_path)\n",
        "collection = client.get_collection(name=\"recommendations\")\n",
        "\n",
        "# 🚀 ฟังก์ชัน RAG (Retrieve) เพื่อค้นหาคำแนะนำที่ใกล้เคียง\n",
        "def retrieve_recommendations(query_embedding, top_k=10):\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "# 🚀 ใช้ RAG ค้นหาคำแนะนำสำหรับทุกคำถามใน Dataset\n",
        "rag_results = []\n",
        "\n",
        "print(\"🔄 กำลังดึงคำแนะนำที่ใกล้เคียงด้วย RAG...\")\n",
        "\n",
        "for idx, item in enumerate(evaluation_data, 1):\n",
        "    query_embedding = item['embedding']\n",
        "    recommendations = retrieve_recommendations(query_embedding, top_k=10)\n",
        "\n",
        "    rag_results.append({\n",
        "        \"question\": item['question'],\n",
        "        \"answer\": item['answer'],\n",
        "        \"category\": item['category'],\n",
        "        \"recommendations\": recommendations\n",
        "    })\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(evaluation_data):\n",
        "        print(f\"✅ ประมวลผลแล้ว {idx}/{len(evaluation_data)} คำถาม\")\n",
        "\n",
        "# 🚀 บันทึกผลลัพธ์ RAG\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_MiniLM_K=10.json'\n",
        "with open(rag_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(rag_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f'✅ บันทึกผลลัพธ์ RAG ที่: {rag_results_file}')\n"
      ],
      "metadata": {
        "id": "3MocKppNUd4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "หาค่า Recall"
      ],
      "metadata": {
        "id": "fsKNg-SmUnH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 🚀 โหลดไฟล์ evaluation dataset (คำถาม-คำตอบจริง)\n",
        "evaluation_file = '/content/drive/MyDrive/LockLearn/evaluation_dataset_with_embeddings_v2_MiniLM.json'\n",
        "with open(evaluation_file, 'r', encoding='utf-8') as f:\n",
        "    evaluation_data = json.load(f)\n",
        "\n",
        "# 🚀 โหลดไฟล์ผลลัพธ์ RAG (คำถาม + คำแนะนำที่ดึงมา)\n",
        "rag_results_file = '/content/drive/MyDrive/LockLearn/evaluation_rag_results_v2_MiniLM_K=10.json'\n",
        "with open(rag_results_file, 'r', encoding='utf-8') as f:\n",
        "    rag_results = json.load(f)\n",
        "\n",
        "K = 10  # จำนวนคำแนะนำที่ดึงมา (top_k)\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Precision@K\n",
        "def precision_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Recall@K\n",
        "def recall_at_k(relevant, retrieved, k):\n",
        "    retrieved_k = retrieved[:k]\n",
        "    hits = sum(1 for r in retrieved_k if r in relevant)\n",
        "    return hits / len(relevant) if relevant else 0\n",
        "\n",
        "# 🚀 ฟังก์ชันคำนวณ Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(relevant, retrieved):\n",
        "    for idx, rec in enumerate(retrieved, 1):\n",
        "        if rec in relevant:\n",
        "            return 1 / idx\n",
        "    return 0\n",
        "\n",
        "# 🚀 เก็บผลลัพธ์คำนวณต่างๆ\n",
        "precisions = []\n",
        "recalls = []\n",
        "mrrs = []\n",
        "\n",
        "print(\"🔄 กำลังคำนวณ Precision, Recall, และ MRR...\")\n",
        "\n",
        "for idx, item in enumerate(rag_results, 1):\n",
        "    # ตรวจสอบว่ามีคำตอบและคำแนะนำหรือไม่\n",
        "    if 'answer' not in item or 'recommendations' not in item:\n",
        "        print(f\"⚠️ ข้อที่ {idx} ไม่มีคำตอบหรือคำแนะนำ ข้ามไป...\")\n",
        "        continue\n",
        "\n",
        "    # คำตอบจริง (ในรูปแบบ list เพื่อรองรับหลายคำตอบในอนาคต)\n",
        "    relevant_answers = [item['answer']] if isinstance(item['answer'], str) else item['answer']\n",
        "\n",
        "    # คำแนะนำที่ดึงมา (list of strings)\n",
        "    retrieved = item['recommendations']\n",
        "\n",
        "    # คำนวณ Metrics\n",
        "    p = precision_at_k(relevant_answers, retrieved, K)\n",
        "    r = recall_at_k(relevant_answers, retrieved, K)\n",
        "    mrr = mean_reciprocal_rank(relevant_answers, retrieved)\n",
        "\n",
        "    precisions.append(p)\n",
        "    recalls.append(r)\n",
        "    mrrs.append(mrr)\n",
        "\n",
        "    if idx % 100 == 0 or idx == len(rag_results):\n",
        "        print(f\"✅ ประมวลผลแล้ว {idx}/{len(rag_results)} คำถาม\")\n",
        "\n",
        "# 🚀 คำนวณค่าเฉลี่ยของ Precision, Recall, MRR ทั้งหมด\n",
        "avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "avg_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
        "\n",
        "print(\"\\n🔎 ผลลัพธ์การประเมินผลด้วย RAG\")\n",
        "print(f\"Precision@{K}: {avg_precision:.3f}\")\n",
        "print(f\"Recall@{K}: {avg_recall:.3f}\")\n",
        "print(f\"Mean Reciprocal Rank (MRR): {avg_mrr:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVPRFNahUp21",
        "outputId": "b6de714f-cfd9-4418-cee1-a9365e02e29c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 กำลังคำนวณ Precision, Recall, และ MRR...\n",
            "✅ ประมวลผลแล้ว 100/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 200/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 300/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 400/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 500/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 600/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 700/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 800/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 900/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1000/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1100/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1200/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1300/1370 คำถาม\n",
            "✅ ประมวลผลแล้ว 1370/1370 คำถาม\n",
            "\n",
            "🔎 ผลลัพธ์การประเมินผลด้วย RAG\n",
            "Precision@10: 0.050\n",
            "Recall@10: 0.504\n",
            "Mean Reciprocal Rank (MRR): 0.342\n"
          ]
        }
      ]
    }
  ]
}